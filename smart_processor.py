import pandas as pd
import openpyxl
from openpyxl.styles import PatternFill
from pathlib import Path
import logging
import re
from config import Config


class SmartReportProcessor:
    def __init__(self):
        self.config = Config()
        self.setup_logging()
        self.ensure_directories()

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.DEBUG,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('processor.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        for dir_path in [self.config.SOURCE_DIR, self.config.TEMPLATE_DIR, self.config.OUTPUT_DIR]:
            Path(dir_path).mkdir(exist_ok=True)

    def debug_dataframe(self, df, title="DataFrameè°ƒè¯•ä¿¡æ¯"):
        """è°ƒè¯•DataFrameå†…å®¹"""
        self.logger.debug(f"\n=== {title} ===")
        self.logger.debug(f"DataFrameå½¢çŠ¶: {df.shape}")
        self.logger.debug(f"å‰10è¡Œæ•°æ®:")
        for i in range(min(10, len(df))):
            row_data = df.iloc[i].tolist()
            self.logger.debug(f"ç¬¬{i}è¡Œ: {row_data}")
        self.logger.debug("=" * 50)

    def read_source_data(self, file_path):
        """è¯»å–åŸå§‹æ•°æ®"""
        try:
            df = pd.read_excel(file_path, sheet_name=self.config.SOURCE_SHEET_NAME, header=None)
            self.logger.info(f"æˆåŠŸè¯»å–æºæ–‡ä»¶: {file_path}")
            self.debug_dataframe(df, f"åŸå§‹æ•°æ® - {file_path.name}")
            return df
        except Exception as e:
            self.logger.error(f"è¯»å–æºæ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return None

    def extract_test_info(self, df):
        """æå–æµ‹è¯•ä¿¡æ¯ - ä½¿ç”¨é…ç½®çš„ä½ç½®"""
        test_info = {}
        pos = self.config.SOURCE_DATA_POSITIONS

        try:
            self.logger.debug(f"å¼€å§‹æå–æµ‹è¯•ä¿¡æ¯ï¼Œä½¿ç”¨ä½ç½®é…ç½®: {pos}")

            required_rows = max(pos['item_name_row'], pos['bias1_row'], pos['bias2_row'],
                                pos['bias3_row'], pos['min_limit_row'], pos['max_limit_row'])

            if len(df) <= required_rows:
                self.logger.error(f"DataFrameè¡Œæ•°ä¸è¶³ï¼Œéœ€è¦è‡³å°‘{required_rows + 1}è¡Œï¼Œå®é™…åªæœ‰{len(df)}è¡Œ")
                return test_info

            item_names = df.iloc[pos['item_name_row'], pos['test_items_start_col']:].tolist()
            bias1_data = df.iloc[pos['bias1_row'], pos['test_items_start_col']:].tolist()
            bias2_data = df.iloc[pos['bias2_row'], pos['test_items_start_col']:].tolist()
            bias3_data = df.iloc[pos['bias3_row'], pos['test_items_start_col']:].tolist()
            min_limits = df.iloc[pos['min_limit_row'], pos['test_items_start_col']:].tolist()
            max_limits = df.iloc[pos['max_limit_row'], pos['test_items_start_col']:].tolist()

            self.logger.debug(f"æµ‹è¯•é¡¹ç›®åç§°: {item_names[:5]}...")
            self.logger.debug(f"Bias1æ•°æ®: {bias1_data[:5]}...")
            self.logger.debug(f"æœ€å°é™å€¼: {min_limits[:5]}...")
            self.logger.debug(f"æœ€å¤§é™å€¼: {max_limits[:5]}...")

            for i, item_name in enumerate(item_names):
                if pd.notna(item_name) and str(item_name).strip():
                    clean_name = str(item_name).strip()
                    test_info[clean_name] = {
                        'bias1': bias1_data[i] if i < len(bias1_data) else '',
                        'bias2': bias2_data[i] if i < len(bias2_data) else '',
                        'bias3': bias3_data[i] if i < len(bias3_data) else '',
                        'min_limit': min_limits[i] if i < len(min_limits) else None,
                        'max_limit': max_limits[i] if i < len(max_limits) else None,
                        'column_index': pos['test_items_start_col'] + i
                    }
                    self.logger.debug(f"æ·»åŠ æµ‹è¯•é¡¹: {clean_name} -> åˆ—{pos['test_items_start_col'] + i}")

            self.logger.info(f"æå–åˆ° {len(test_info)} ä¸ªæµ‹è¯•é¡¹ç›®")
            self.logger.debug(f"æµ‹è¯•é¡¹ç›®åˆ—è¡¨: {list(test_info.keys())}")

        except Exception as e:
            self.logger.error(f"æå–æµ‹è¯•ä¿¡æ¯å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯:")

        return test_info

    def extract_test_data(self, df):
        """æå–æµ‹è¯•æ•°æ® - æ”¯æŒPæˆ–Få‰ç¼€"""
        test_data = []
        pos = self.config.SOURCE_DATA_POSITIONS
        recognition = self.config.DATA_RECOGNITION

        try:
            self.logger.debug(f"å¼€å§‹æå–æµ‹è¯•æ•°æ®ï¼Œä»ç¬¬{pos['data_start_row']}è¡Œå¼€å§‹")

            # ğŸ†• è·å–æ”¯æŒçš„å‰ç¼€ï¼Œæ”¯æŒPæˆ–F
            sample_prefix = recognition['sample_prefix']
            if isinstance(sample_prefix, str):
                # å¦‚æœæ˜¯å•ä¸ªå‰ç¼€ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨ä»¥æ”¯æŒå¤šå‰ç¼€æ£€æŸ¥
                supported_prefixes = [sample_prefix]
            else:
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                supported_prefixes = sample_prefix

            # ğŸ†• æ·»åŠ Få‰ç¼€æ”¯æŒ
            if 'P' in supported_prefixes and 'F' not in supported_prefixes:
                supported_prefixes.append('F')
            elif 'F' in supported_prefixes and 'P' not in supported_prefixes:
                supported_prefixes.append('P')
            elif sample_prefix == 'P':
                supported_prefixes = ['P', 'F']

            self.logger.debug(f"æ”¯æŒçš„æ ·å“å‰ç¼€: {supported_prefixes}")

            start_row = pos['data_start_row']
            max_rows = start_row + recognition['max_data_rows']

            for idx in range(start_row, min(len(df), max_rows)):
                row_data = df.iloc[idx].tolist()

                if len(row_data) > pos['sample_id_col']:
                    sample_id = row_data[pos['sample_id_col']]

                    self.logger.debug(f"ç¬¬{idx}è¡Œï¼Œæ ·å“ID: {sample_id}")

                    # ğŸ†• æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ”¯æŒçš„å‰ç¼€
                    if pd.notna(sample_id):
                        sample_id_str = str(sample_id).strip()
                        is_valid_sample = False

                        for prefix in supported_prefixes:
                            if sample_id_str.startswith(prefix):
                                is_valid_sample = True
                                self.logger.debug(f"æ ·å“ {sample_id} åŒ¹é…å‰ç¼€ {prefix}")
                                break

                        if is_valid_sample:
                            test_data.append(row_data)
                            self.logger.debug(f"æ·»åŠ æµ‹è¯•æ•°æ®è¡Œ: {sample_id}")

                    elif recognition['auto_detect_data_end'] and not pd.notna(sample_id):
                        if recognition['skip_empty_rows']:
                            continue
                        else:
                            self.logger.debug(f"é‡åˆ°ç©ºè¡Œï¼Œåœæ­¢æ•°æ®æå–")
                            break

            self.logger.info(f"æå–åˆ° {len(test_data)} è¡Œæµ‹è¯•æ•°æ®")

            for i, row in enumerate(test_data[:3]):
                self.logger.debug(f"æµ‹è¯•æ•°æ®ç¬¬{i + 1}è¡Œ: {row[:10]}...")

        except Exception as e:
            self.logger.error(f"æå–æµ‹è¯•æ•°æ®å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯:")

        return test_data

    def map_to_template_items(self, test_info):
        """å°†åŸå§‹æµ‹è¯•é¡¹æ˜ å°„åˆ°æ¨¡æ¿æµ‹è¯•é¡¹"""
        template_data = {}
        processing = self.config.DATA_PROCESSING

        self.logger.debug(f"å¼€å§‹æ˜ å°„æµ‹è¯•é¡¹ï¼Œæ˜ å°„è§„åˆ™: {self.config.TEST_ITEMS_MAPPING}")

        for template_item, source_items in self.config.TEST_ITEMS_MAPPING.items():
            template_data[template_item] = {
                'conditions': [],
                'min_limits': [],
                'max_limits': [],
                'source_columns': []
            }

            self.logger.debug(f"å¤„ç†æ¨¡æ¿é¡¹: {template_item}")

            for source_item in source_items:
                if source_item in test_info:
                    info = test_info[source_item]

                    # å¤„ç†æµ‹è¯•æ¡ä»¶ï¼Œæ”¯æŒåˆ†è¡Œæ˜¾ç¤º
                    condition_parts = []
                    for bias_key in ['bias1', 'bias2', 'bias3']:
                        bias_value = info.get(bias_key, '')
                        if bias_value and str(bias_value).strip() and str(bias_value).strip() != 'nan':
                            condition_parts.append(str(bias_value).strip())

                    # å¦‚æœå¯ç”¨åˆ†è¡Œæ˜¾ç¤ºï¼Œæ¯ä¸ªæ¡ä»¶å•ç‹¬å­˜å‚¨
                    if processing['conditions_multiline']:
                        template_data[template_item]['conditions'].extend(condition_parts)
                    else:
                        condition_text = processing['combine_conditions_separator'].join(condition_parts)
                        template_data[template_item]['conditions'].append(condition_text)

                    template_data[template_item]['min_limits'].append(info['min_limit'])
                    template_data[template_item]['max_limits'].append(info['max_limit'])
                    template_data[template_item]['source_columns'].append(info['column_index'])

                    self.logger.debug(f"  æ‰¾åˆ°æºé¡¹: {source_item} -> åˆ—{info['column_index']}")
                else:
                    self.logger.warning(f"  æœªæ‰¾åˆ°æºé¡¹: {source_item}")

        for item, data in template_data.items():
            self.logger.debug(f"æ¨¡æ¿é¡¹ {item}: æºåˆ—{data['source_columns']}, æ¡ä»¶æ•°{len(data['conditions'])}")

        return template_data

    def is_valid_value(self, value):
        """æ£€æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆï¼ˆåŒ…æ‹¬æ•°å€¼0å’Œ"Over"ï¼‰"""
        if pd.isna(value):
            return False

        value_str = str(value).strip()
        if not value_str or value_str.lower() in ['nan', 'n/a', '']:
            return False

        # ğŸ†• æ–°å¢ï¼šå¤„ç†"Over"å€¼
        if value_str.upper() == "OVER":
            return True

        # æ•°å€¼0æ˜¯æœ‰æ•ˆå€¼
        try:
            float_val = float(
                value_str.replace('V', '').replace('A', '').replace('R', '').replace('mV', '').replace('uA',
                                                                                                       '').replace('nA',
                                                                                                                   '').replace(
                    'mR', '').replace('ohm', '').replace('Î©', ''))
            return True
        except:
            return len(value_str) > 0

    def convert_to_numeric(self, value_str):
        """å°†å­—ç¬¦ä¸²å€¼è½¬æ¢ä¸ºæ•°å€¼å½¢å¼ï¼Œä¿ç•™0å€¼å’Œ"Over"å€¼"""
        if not self.is_valid_value(value_str):
            return None

        value_str = str(value_str).strip()

        # ğŸ†• æ–°å¢ï¼šç›´æ¥è¿”å›"Over"å€¼
        if value_str.upper() == "OVER":
            return "Over"

        try:
            original_value = value_str
            clean_value = value_str

            # ç§»é™¤å•ä½ç¬¦å·ä½†ä¿æŒæ•°å€¼ä¸å˜
            for unit_type, units in self.config.VALUE_PROCESSING['unit_patterns'].items():
                for unit in units:
                    clean_value = clean_value.replace(unit, '')

            # è½¬æ¢ä¸ºæ•°å€¼
            numeric_value = float(clean_value.strip())

            # æ ¹æ®é…ç½®å†³å®šç²¾åº¦
            if self.config.DATA_PROCESSING['convert_to_numeric']:
                precision = self.config.VALUE_PROCESSING['decimal_places']
                if abs(numeric_value) < self.config.VALUE_PROCESSING[
                    'scientific_notation_threshold'] and numeric_value != 0:
                    return f"{numeric_value:.{precision}e}"
                else:
                    return round(numeric_value, precision)
            else:
                return original_value

        except (ValueError, TypeError):
            self.logger.debug(f"æ— æ³•è½¬æ¢ä¸ºæ•°å€¼: {value_str}")
            return value_str if not self.config.VALUE_PROCESSING['force_numeric_output'] else None

    def clean_numeric_value(self, value_str):
        """æ¸…ç†æ•°å€¼å­—ç¬¦ä¸²ï¼Œç”¨äºé™å€¼æ¯”è¾ƒï¼Œ"Over"å€¼è¿”å›ç‰¹æ®Šæ ‡è®°"""
        if not self.is_valid_value(value_str):
            return None

        value_str = str(value_str).strip()

        # ğŸ†• å¯¹äºOverå€¼ï¼Œè¿”å›æ— ç©·å¤§ç”¨äºæ¯”è¾ƒ
        if self.is_over_value(value_str):
            return float('inf')  # è¿”å›æ— ç©·å¤§ï¼Œè¡¨ç¤ºè¶…å‡ºæ‰€æœ‰é™å€¼

        try:
            # ç§»é™¤å•ä½ç¬¦å·ä½†ä¸è¿›è¡Œå•ä½è½¬æ¢
            clean_value = value_str
            for unit_type, units in self.config.VALUE_PROCESSING['unit_patterns'].items():
                for unit in units:
                    clean_value = clean_value.replace(unit, '')

            return float(clean_value.strip())
        except (ValueError, TypeError):
            return None

    def count_abnormal_data(self, test_data, template_data):
        """ç»Ÿè®¡å¼‚å¸¸æ•°æ®è¡Œæ•°ï¼ˆåŒä¸€è¡Œå¤šä¸ªå¼‚å¸¸åªè®¡ç®—ä¸€æ¬¡ï¼ŒåŒ…æ‹¬Overå€¼ï¼‰- æ”¯æŒPæˆ–Få‰ç¼€ï¼Œç»å¯¹å€¼æ¯”è¾ƒ"""
        try:
            if not self.config.ABNORMAL_STATISTICS.get('enable_counting', True):
                return 0

            abnormal_count = 0
            sample_id_col_pos = self.config.SOURCE_DATA_POSITIONS['sample_id_col']
            recognition = self.config.DATA_RECOGNITION
            
            # è·å–æ”¯æŒçš„å‰ç¼€ï¼Œæ”¯æŒPæˆ–F
            sample_prefix = recognition['sample_prefix']
            if isinstance(sample_prefix, str):
                supported_prefixes = [sample_prefix]
            else:
                supported_prefixes = sample_prefix
            
            # æ·»åŠ Få‰ç¼€æ”¯æŒ
            if 'P' in supported_prefixes and 'F' not in supported_prefixes:
                supported_prefixes.append('F')
            elif 'F' in supported_prefixes and 'P' not in supported_prefixes:
                supported_prefixes.append('P')
            elif sample_prefix == 'P':
                supported_prefixes = ['P', 'F']

            # è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            abnormal_samples = []
            over_count = 0
            range_abnormal_count = 0

            self.logger.debug(f"å¼€å§‹ç»Ÿè®¡å¼‚å¸¸æ•°æ®ï¼Œæ•°æ®è¡Œæ•°: {len(test_data)}")
            self.logger.debug(f"æ”¯æŒçš„æ ·å“å‰ç¼€: {supported_prefixes}")
            self.logger.debug("ğŸ†• ä½¿ç”¨ç»å¯¹å€¼æ¯”è¾ƒæ¨¡å¼")

            for test_row in test_data:
                if len(test_row) <= sample_id_col_pos:
                    continue

                sample_id = str(test_row[sample_id_col_pos])
                
                # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ”¯æŒçš„å‰ç¼€
                is_valid_sample = False
                for prefix in supported_prefixes:
                    if sample_id.strip().startswith(prefix):
                        is_valid_sample = True
                        break
                
                if not is_valid_sample:
                    continue

                # æ£€æŸ¥è¿™ä¸€è¡Œæ˜¯å¦æœ‰ä»»ä½•å¼‚å¸¸
                has_abnormal = False
                sample_abnormal_items = []

                for item_name, data in template_data.items():
                    for source_col in data['source_columns']:
                        if source_col < len(test_row):
                            val = test_row[source_col]

                            if self.is_valid_value(val):
                                # ä¼˜å…ˆæ£€æŸ¥Overå€¼
                                if self.is_over_value(val):
                                    has_abnormal = True
                                    over_count += 1
                                    sample_abnormal_items.append(f"{item_name}={val}(Over)")
                                    self.logger.debug(f"æ ·å“ {sample_id} å‘ç°Overå€¼: {item_name}={val}")
                                    break

                                # ğŸ†• æ£€æŸ¥æ•°å€¼èŒƒå›´å¼‚å¸¸ï¼ˆä½¿ç”¨ç»å¯¹å€¼æ¯”è¾ƒï¼‰
                                clean_val = self.clean_numeric_value(val)
                                if clean_val is not None:
                                    if self.is_value_abnormal(clean_val, data):
                                        has_abnormal = True
                                        range_abnormal_count += 1
                                        # ğŸ†• åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºç»å¯¹å€¼æ¯”è¾ƒä¿¡æ¯
                                        abs_val = abs(clean_val) if clean_val != float('inf') else clean_val
                                        sample_abnormal_items.append(f"{item_name}={val}(èŒƒå›´,ç»å¯¹å€¼:{abs_val})")
                                        self.logger.debug(f"æ ·å“ {sample_id} å‘ç°èŒƒå›´å¼‚å¸¸: {item_name}={val} (ç»å¯¹å€¼:{abs_val})")
                                        break

                    if has_abnormal:
                        break

                if has_abnormal:
                    abnormal_count += 1
                    abnormal_samples.append({
                        'sample_id': sample_id,
                        'abnormal_items': sample_abnormal_items
                    })
                    self.logger.debug(f"å‘ç°å¼‚å¸¸è¡Œ: {sample_id}")

            # è¯¦ç»†ç»Ÿè®¡æ—¥å¿—
            self.logger.info(f"å¼‚å¸¸ç»Ÿè®¡å®Œæˆ - æ€»å¼‚å¸¸æ•°é‡: {abnormal_count}")
            self.logger.info(f"ç»Ÿè®¡è¯¦æƒ… - Overå€¼: {over_count}, èŒƒå›´å¼‚å¸¸(ç»å¯¹å€¼æ¯”è¾ƒ): {range_abnormal_count}")
            self.logger.info(f"å¼‚å¸¸æ ·å“æ•°é‡: {len(abnormal_samples)}")

            if self.config.LOGGING.get('log_statistics', True):
                for abnormal_sample in abnormal_samples:
                    self.logger.debug(
                        f"å¼‚å¸¸æ ·å“ {abnormal_sample['sample_id']}: {', '.join(abnormal_sample['abnormal_items'])}")

            return abnormal_count

        except Exception as e:
            self.logger.error(f"ç»Ÿè®¡å¼‚å¸¸æ•°æ®å¤±è´¥: {str(e)}")
            return 0

    def is_over_value(self, value):
        """æ£€æŸ¥æ˜¯å¦ä¸ºOverå€¼ - ä½¿ç”¨é…ç½®çš„æ¨¡å¼"""
        try:
            if isinstance(value, str):
                value_str = str(value).strip()

                # ğŸ†• ä½¿ç”¨é…ç½®ä¸­çš„Overå€¼æ¨¡å¼
                over_patterns = self.config.DATA_RECOGNITION.get('over_value_patterns',
                                                                 ['OVER', 'Over', 'over'])

                for pattern in over_patterns:
                    if pattern in value_str:
                        return True

                # æ£€æŸ¥æ˜¯å¦ä»¥>å¼€å¤´çš„æ•°å€¼
                if value_str.startswith('>'):
                    return True

            return False

        except Exception as e:
            self.logger.warning(f"æ£€æŸ¥Overå€¼æ—¶å‡ºé”™: {str(e)}")
            return False

    def is_value_abnormal(self, numeric_value, limit_data):
        """åˆ¤æ–­å•ä¸ªæ•°å€¼æ˜¯å¦å¼‚å¸¸ - åªæ¯”è¾ƒç»å¯¹å€¼å¤§å°"""
        try:
            # ğŸ†• å–ç»å¯¹å€¼è¿›è¡Œæ¯”è¾ƒ
            abs_value = abs(numeric_value) if numeric_value != float('inf') else numeric_value
            
            # æ£€æŸ¥æœ€å°é™å€¼
            for min_limit in limit_data['min_limits']:
                if min_limit is not None:
                    min_val = self.clean_numeric_value(min_limit)
                    if min_val is not None:
                        # ğŸ†• å–ç»å¯¹å€¼æ¯”è¾ƒ
                        abs_min_val = abs(min_val)
                        if abs_value < abs_min_val:
                            self.logger.debug(f"ç»å¯¹å€¼ {abs_value} ä½äºæœ€å°é™å€¼ç»å¯¹å€¼ {abs_min_val}")
                            return True

            # æ£€æŸ¥æœ€å¤§é™å€¼
            for max_limit in limit_data['max_limits']:
                if max_limit is not None:
                    max_val = self.clean_numeric_value(max_limit)
                    if max_val is not None:
                        # ğŸ†• å–ç»å¯¹å€¼æ¯”è¾ƒ
                        abs_max_val = abs(max_val)
                        if abs_value > abs_max_val:
                            self.logger.debug(f"ç»å¯¹å€¼ {abs_value} è¶…è¿‡æœ€å¤§é™å€¼ç»å¯¹å€¼ {abs_max_val}")
                            return True

            return False
        except Exception as e:
            self.logger.warning(f"åˆ¤æ–­å¼‚å¸¸å€¼å¤±è´¥: {str(e)}")
            return False

    def filter_group_test_data(self, test_data, start_sample, end_sample):
        """ç­›é€‰æŒ‡å®šæ•°æ®ç»„çš„æµ‹è¯•æ•°æ® - æ”¯æŒPæˆ–Få‰ç¼€"""
        try:
            filtered_data = []
            recognition = self.config.DATA_RECOGNITION
            sample_id_col_pos = self.config.SOURCE_DATA_POSITIONS['sample_id_col']

            # ğŸ†• è·å–æ”¯æŒçš„å‰ç¼€ï¼Œæ”¯æŒPæˆ–F
            sample_prefix = recognition['sample_prefix']
            if isinstance(sample_prefix, str):
                supported_prefixes = [sample_prefix]
            else:
                supported_prefixes = sample_prefix

            # ğŸ†• æ·»åŠ Få‰ç¼€æ”¯æŒ
            if 'P' in supported_prefixes and 'F' not in supported_prefixes:
                supported_prefixes.append('F')
            elif 'F' in supported_prefixes and 'P' not in supported_prefixes:
                supported_prefixes.append('P')
            elif sample_prefix == 'P':
                supported_prefixes = ['P', 'F']

            # ä½¿ç”¨ä¸»è¦å‰ç¼€è¿›è¡ŒèŒƒå›´æ˜¾ç¤º
            primary_prefix = supported_prefixes[0] if supported_prefixes else 'P'

            self.logger.debug(f"å¼€å§‹ç­›é€‰æ•°æ®ç»„ {primary_prefix}{start_sample}-{primary_prefix}{end_sample}")
            self.logger.debug(f"æ”¯æŒçš„å‰ç¼€: {supported_prefixes}")

            for test_row in test_data:
                if len(test_row) > sample_id_col_pos:
                    sample_id = str(test_row[sample_id_col_pos])

                    # ğŸ†• æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ”¯æŒçš„å‰ç¼€
                    matched_prefix = None
                    sample_num = None

                    for prefix in supported_prefixes:
                        if sample_id.startswith(prefix):
                            matched_prefix = prefix
                            try:
                                # æå–æ ·å“ç¼–å·
                                sample_num_str = sample_id[len(prefix):]
                                sample_num = int(sample_num_str)
                                break
                            except ValueError:
                                self.logger.warning(f"æ— æ³•è§£ææ ·å“ç¼–å·: {sample_id}")
                                continue

                    if matched_prefix and sample_num is not None:
                        # ğŸ†• æ£€æŸ¥æ˜¯å¦åœ¨å½“å‰æ•°æ®ç»„èŒƒå›´å†…
                        if start_sample <= sample_num <= end_sample:
                            filtered_data.append(test_row)
                            self.logger.debug(f"æ ·å“ {sample_id} (å‰ç¼€:{matched_prefix}) åŒ…å«åœ¨æ•°æ®ç»„èŒƒå›´å†…")
                        else:
                            self.logger.debug(f"æ ·å“ {sample_id} ä¸åœ¨æ•°æ®ç»„èŒƒå›´å†…ï¼Œè·³è¿‡")
                    else:
                        self.logger.debug(f"æ ·å“ {sample_id} ä¸ç¬¦åˆå‰ç¼€è§„åˆ™ï¼Œè·³è¿‡")

            self.logger.info(
                f"æ•°æ®ç»„ {primary_prefix}{start_sample}-{primary_prefix}{end_sample} ç­›é€‰å®Œæˆï¼ŒåŒ…å« {len(filtered_data)} è¡Œæ•°æ®")

            return filtered_data

        except Exception as e:
            self.logger.error(f"ç­›é€‰æ•°æ®ç»„æ•°æ®å¤±è´¥: {str(e)}")
            return []

    def write_to_template(self, template_path, output_path, template_data, test_data):
        """å†™å…¥æ¨¡æ¿å¹¶ç”ŸæˆæŠ¥å‘Š"""
        try:
            self.logger.info(f"å¼€å§‹å†™å…¥æ¨¡æ¿: {template_path}")
            self.logger.info(f"æ€»æµ‹è¯•æ•°æ®è¡Œæ•°: {len(test_data)}")

            workbook = openpyxl.load_workbook(template_path)
            self.logger.debug(f"æ¨¡æ¿å·¥ä½œè¡¨: {workbook.sheetnames}")

            # ğŸ†• ç§»é™¤å…¨å±€å¼‚å¸¸ç»Ÿè®¡ï¼Œæ”¹ä¸ºåˆ†ç»„ç»Ÿè®¡
            # abnormal_count = self.count_abnormal_data(test_data, template_data)  # åˆ é™¤è¿™è¡Œ

            # ğŸ†• ä¸ºæ¯ä¸ªæ•°æ®ç»„åˆ†åˆ«ç»Ÿè®¡å¼‚å¸¸æ•°é‡
            for group_name, group_config in self.config.DATA_GROUPS.items():
                sheet_index = group_config['target_sheet']
                if sheet_index < len(workbook.worksheets):
                    sheet = workbook.worksheets[sheet_index]
                    self.logger.info(f"å¤„ç†æ•°æ®ç»„: {group_name} -> å·¥ä½œè¡¨{sheet_index}({sheet.title})")

                    # ğŸ†• è·å–å½“å‰æ•°æ®ç»„çš„æ•°æ®èŒƒå›´
                    start_sample, end_sample = group_config['range']
                    self.logger.info(f"æ•°æ®ç»„èŒƒå›´: P{start_sample}-P{end_sample}")

                    # ğŸ†• ç­›é€‰å½“å‰æ•°æ®ç»„çš„æµ‹è¯•æ•°æ®
                    group_test_data = self.filter_group_test_data(test_data, start_sample, end_sample)
                    self.logger.info(f"æ•°æ®ç»„ {group_name} ç­›é€‰å‡º {len(group_test_data)} è¡Œæ•°æ®")

                    # ğŸ†• ç»Ÿè®¡å½“å‰æ•°æ®ç»„çš„å¼‚å¸¸æ•°é‡
                    group_abnormal_count = self.count_abnormal_data(group_test_data, template_data)

                    # å†™å…¥æ•°æ®ç»„æ•°æ®
                    self.write_group_data(sheet, template_data, test_data, group_config)

                    # ğŸ†• å†™å…¥å½“å‰æ•°æ®ç»„çš„å¼‚å¸¸ç»Ÿè®¡
                    self.write_abnormal_count(sheet, group_abnormal_count, sheet_index)

                    self.logger.info(f"æ•°æ®ç»„ {group_name} å¤„ç†å®Œæˆ")
                    self.logger.info(f"  - æ ·å“èŒƒå›´: P{start_sample}-P{end_sample}")
                    self.logger.info(f"  - æ•°æ®è¡Œæ•°: {len(group_test_data)}")
                    self.logger.info(f"  - å¼‚å¸¸æ•°é‡: {group_abnormal_count}")
                    self.logger.info("-" * 50)
                else:
                    self.logger.error(f"å·¥ä½œè¡¨ç´¢å¼•{sheet_index}è¶…å‡ºèŒƒå›´ï¼Œæ€»å…±{len(workbook.worksheets)}ä¸ªå·¥ä½œè¡¨")

            workbook.save(output_path)
            self.logger.info(f"æˆåŠŸç”ŸæˆæŠ¥å‘Š: {output_path}")

        except Exception as e:
            self.logger.error(f"å†™å…¥æ¨¡æ¿å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")

    def write_abnormal_count(self, sheet, abnormal_count, sheet_index=0):
        """å†™å…¥å¼‚å¸¸ç»Ÿè®¡åˆ°æŒ‡å®šä½ç½®ï¼ˆæ•°å€¼å½¢å¼ï¼Œä¸æ”¹å˜æ ¼å¼ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¼‚å¸¸ç»Ÿè®¡
            if not self.config.ABNORMAL_STATISTICS.get('enable_counting', True):
                self.logger.debug("å¼‚å¸¸ç»Ÿè®¡åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡å†™å…¥")
                return

            if not self.config.ABNORMAL_STATISTICS.get('write_to_template', True):
                self.logger.debug("å¼‚å¸¸ç»Ÿè®¡å†™å…¥æ¨¡æ¿åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡å†™å…¥")
                return

            # è·å–å¯¹åº”å·¥ä½œè¡¨çš„ä½ç½®é…ç½®
            positions = self.config.ABNORMAL_STATISTICS.get('positions', {})
            sheet_key = f"sheet_{sheet_index}"

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”å·¥ä½œè¡¨çš„é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            if sheet_key not in positions:
                self.logger.warning(f"æœªæ‰¾åˆ°å·¥ä½œè¡¨{sheet_index}çš„å¼‚å¸¸ç»Ÿè®¡ä½ç½®é…ç½®ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®")
                position_config = {
                    "row": 1,
                    "col": 1,
                    "write_as_number": True
                }
            else:
                position_config = positions[sheet_key]

            # è·å–ä½ç½®ä¿¡æ¯
            abnormal_row = position_config.get('row', 1)
            abnormal_col = position_config.get('col', 1)
            write_as_number = position_config.get('write_as_number', True)

            # ğŸ†• æ ¹æ®é…ç½®å†³å®šå†™å…¥æ ¼å¼
            if write_as_number:
                # ğŸ†• ç›´æ¥å†™å…¥æ•°å€¼ï¼Œä¸æ”¹å˜ä»»ä½•æ ¼å¼
                cell_value = abnormal_count
                display_info = f"æ•°å€¼: {abnormal_count}"
            else:
                # å†™å…¥æ ¼å¼åŒ–æ–‡æœ¬ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
                format_template = position_config.get('format', "å¼‚å¸¸æ•°é‡: {count}")
                cell_value = format_template.format(count=abnormal_count)
                display_info = f"æ–‡æœ¬: {cell_value}"

            # ğŸ†• åªå†™å…¥å€¼ï¼Œä¸ä¿®æ”¹ä»»ä½•æ ¼å¼
            sheet.cell(row=abnormal_row, column=abnormal_col, value=cell_value)

            # ğŸ†• ç§»é™¤æ‰€æœ‰æ ¼å¼è®¾ç½®ä»£ç ï¼Œä¿æŒåŸæœ‰æ ¼å¼ä¸å˜
            # ä¸å†è®¾ç½®å­—ä½“ã€é¢œè‰²ã€å¯¹é½ç­‰æ ¼å¼

            self.logger.info(f"å¼‚å¸¸ç»Ÿè®¡å·²å†™å…¥å·¥ä½œè¡¨{sheet_index}: è¡Œ{abnormal_row}, åˆ—{abnormal_col}, {display_info}")

            # å¦‚æœå¯ç”¨äº†è¯¦ç»†æ—¥å¿—
            if self.config.LOGGING.get('log_statistics', True):
                self.logger.debug(
                    f"å¼‚å¸¸ç»Ÿè®¡è¯¦æƒ… - å·¥ä½œè¡¨: {sheet.title}, ä½ç½®: ({abnormal_row}, {abnormal_col}), æ•°é‡: {abnormal_count}, æ ¼å¼: {'æ•°å€¼' if write_as_number else 'æ–‡æœ¬'}")

        except Exception as e:
            self.logger.error(f"å†™å…¥å¼‚å¸¸ç»Ÿè®¡å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")

    def write_group_data(self, sheet, template_data, test_data, group_config):
        """å†™å…¥åˆ†ç»„æ•°æ®åˆ°æŒ‡å®šè¡¨æ ¼ï¼Œæ”¯æŒPæˆ–Få‰ç¼€"""
        pos = self.config.TEMPLATE_POSITIONS
        processing = self.config.DATA_PROCESSING
        recognition = self.config.DATA_RECOGNITION
        col_offset = pos['test_items_start_col']

        # ğŸ†• è·å–æ”¯æŒçš„å‰ç¼€ï¼Œæ”¯æŒPæˆ–F
        sample_prefix = recognition['sample_prefix']
        if isinstance(sample_prefix, str):
            supported_prefixes = [sample_prefix]
        else:
            supported_prefixes = sample_prefix

        # ğŸ†• æ·»åŠ Få‰ç¼€æ”¯æŒ
        if 'P' in supported_prefixes and 'F' not in supported_prefixes:
            supported_prefixes.append('F')
        elif 'F' in supported_prefixes and 'P' not in supported_prefixes:
            supported_prefixes.append('P')
        elif sample_prefix == 'P':
            supported_prefixes = ['P', 'F']

        self.logger.debug(f"å†™å…¥æ•°æ®åˆ°å·¥ä½œè¡¨: {sheet.title}")
        self.logger.debug(f"æ¨¡æ¿ä½ç½®é…ç½®: {pos}")
        self.logger.debug(f"æ•°æ®ç»„é…ç½®: {group_config}")
        self.logger.debug(f"æ”¯æŒçš„å‰ç¼€: {supported_prefixes}")

        # å†™å…¥æµ‹è¯•é¡¹ç›®åç§°
        for i, item_name in enumerate(self.config.TEST_ITEMS_MAPPING.keys()):
            cell = sheet.cell(row=pos['test_items_row'], column=col_offset + i, value=item_name)
            self.logger.debug(f"å†™å…¥æµ‹è¯•é¡¹ç›®: è¡Œ{pos['test_items_row']}, åˆ—{col_offset + i}, å€¼: {item_name}")

        # å†™å…¥æµ‹è¯•æ¡ä»¶ï¼Œæ”¯æŒåˆ†è¡Œæ˜¾ç¤º
        for i, (item_name, data) in enumerate(template_data.items()):
            col = col_offset + i

            # æµ‹è¯•æ¡ä»¶ - æ”¯æŒåˆ†è¡Œæ˜¾ç¤º
            if data['conditions']:
                if processing['conditions_multiline'] and len(data['conditions']) > 1:
                    # åˆ†è¡Œæ˜¾ç¤ºæµ‹è¯•æ¡ä»¶
                    for j, condition in enumerate(data['conditions'][:pos['test_conditions_max_rows']]):
                        if condition:
                            condition_row = pos['test_conditions_row'] + j
                            sheet.cell(row=condition_row, column=col, value=condition)
                            self.logger.debug(f"å†™å…¥æµ‹è¯•æ¡ä»¶: è¡Œ{condition_row}, åˆ—{col}, å€¼: {condition}")
                else:
                    # å•è¡Œæ˜¾ç¤ºæ‰€æœ‰æ¡ä»¶
                    conditions_text = processing['combine_conditions_separator'].join(
                        [cond for cond in data['conditions'] if cond]
                    )
                    if conditions_text:
                        sheet.cell(row=pos['test_conditions_row'], column=col, value=conditions_text)
                        self.logger.debug(
                            f"å†™å…¥æµ‹è¯•æ¡ä»¶: è¡Œ{pos['test_conditions_row']}, åˆ—{col}, å€¼: {conditions_text}")

            # è§„æ ¼é™å€¼
            if data['min_limits']:
                min_vals = [str(x) for x in data['min_limits'] if x is not None and str(x).strip() != 'nan']
                if min_vals:
                    min_text = processing['combine_values_separator'].join(min_vals)
                    sheet.cell(row=pos['min_limit_row'], column=col, value=min_text)
                    self.logger.debug(f"å†™å…¥æœ€å°é™å€¼: è¡Œ{pos['min_limit_row']}, åˆ—{col}, å€¼: {min_text}")

            if data['max_limits']:
                max_vals = [str(x) for x in data['max_limits'] if x is not None and str(x).strip() != 'nan']
                if max_vals:
                    max_text = processing['combine_values_separator'].join(max_vals)
                    sheet.cell(row=pos['max_limit_row'], column=col, value=max_text)
                    self.logger.debug(f"å†™å…¥æœ€å¤§é™å€¼: è¡Œ{pos['max_limit_row']}, åˆ—{col}, å€¼: {max_text}")

        # å†™å…¥æµ‹è¯•æ•°æ®ï¼Œæ”¯æŒPæˆ–Få‰ç¼€
        start_idx, end_idx = group_config['range']
        data_row = pos['data_start_row']
        sample_id_col_pos = self.config.SOURCE_DATA_POSITIONS['sample_id_col']

        self.logger.debug(f"å¼€å§‹å†™å…¥æµ‹è¯•æ•°æ®ï¼ŒèŒƒå›´: {start_idx}-{end_idx}")

        written_count = 0
        for test_row in test_data:
            if len(test_row) > sample_id_col_pos:
                sample_id = str(test_row[sample_id_col_pos])

                # ğŸ†• æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ”¯æŒçš„å‰ç¼€å¹¶æå–ç¼–å·
                matched_prefix = None
                p_number = None

                for prefix in supported_prefixes:
                    if sample_id.startswith(prefix):
                        matched_prefix = prefix
                        p_num = sample_id.replace(prefix, '')
                        try:
                            p_number = int(p_num)
                            break
                        except ValueError:
                            self.logger.warning(f"æ— æ³•è§£ææ ·å“ç¼–å·: {sample_id}")
                            continue

                if matched_prefix and p_number is not None:
                    if start_idx <= p_number <= end_idx:
                        row_num = p_number - start_idx + 1
                        sheet.cell(row=data_row, column=pos['sample_id_col'], value=row_num)
                        self.logger.debug(f"å†™å…¥æ ·å“{sample_id} (å‰ç¼€:{matched_prefix}): è¡Œ{data_row}, åºå·{row_num}")

                        # å†™å…¥å„æµ‹è¯•é¡¹çš„æ•°æ®
                        for i, (item_name, data) in enumerate(template_data.items()):
                            col = col_offset + i
                            values = []
                            numeric_values = []

                            for source_col in data['source_columns']:
                                if source_col < len(test_row):
                                    val = test_row[source_col]

                                    # å…³é”®ä¿®å¤ï¼šä½¿ç”¨æ–°çš„æœ‰æ•ˆæ€§æ£€æŸ¥ï¼ŒåŒ…æ‹¬0å€¼
                                    if self.is_valid_value(val):
                                        # è½¬æ¢ä¸ºæ•°å€¼å½¢å¼
                                        numeric_val = self.convert_to_numeric(val)
                                        if numeric_val is not None:
                                            values.append(str(numeric_val))
                                            # ç”¨äºé™å€¼æ¯”è¾ƒçš„æ¸…ç†æ•°å€¼
                                            clean_val = self.clean_numeric_value(val)
                                            if clean_val is not None:
                                                numeric_values.append(clean_val)

                                        self.logger.debug(f"    åŸå§‹å€¼: {val}, è½¬æ¢å: {numeric_val}")

                            # å†™å…¥å•å…ƒæ ¼å€¼
                            if values:
                                cell_value = processing['combine_values_separator'].join(values)
                            else:
                                cell_value = processing['empty_value_placeholder']

                            cell = sheet.cell(row=data_row, column=col, value=cell_value)

                            # å¦‚æœåªæœ‰ä¸€ä¸ªæ•°å€¼ä¸”å¯ç”¨äº†æ•°å€¼è½¬æ¢ï¼Œç›´æ¥å†™å…¥æ•°å€¼è€Œä¸æ˜¯å­—ç¬¦ä¸²
                            if (len(values) == 1 and processing['convert_to_numeric']):
                                try:
                                    # ä¿®å¤ï¼šç¡®ä¿0å€¼ä¹Ÿèƒ½æ­£ç¡®å†™å…¥
                                    if values[0] != "Over":  # ğŸ†• Overå€¼ä¿æŒä¸ºæ–‡æœ¬
                                        numeric_cell_value = float(values[0])
                                        cell.value = numeric_cell_value
                                        self.logger.debug(
                                            f"  å†™å…¥æ•°å€¼: è¡Œ{data_row}, åˆ—{col}, é¡¹ç›®{item_name}, æ•°å€¼: {numeric_cell_value}")
                                    else:
                                        self.logger.debug(
                                            f"  å†™å…¥Overå€¼: è¡Œ{data_row}, åˆ—{col}, é¡¹ç›®{item_name}, æ–‡æœ¬: {cell_value}")
                                except:
                                    self.logger.debug(
                                        f"  å†™å…¥æ–‡æœ¬: è¡Œ{data_row}, åˆ—{col}, é¡¹ç›®{item_name}, æ–‡æœ¬: {cell_value}")
                            else:
                                self.logger.debug(
                                    f"  å†™å…¥æ•°æ®: è¡Œ{data_row}, åˆ—{col}, é¡¹ç›®{item_name}, å€¼: {cell_value}")

                            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé™å€¼å¹¶é«˜äº®
                            self.check_and_highlight(cell, numeric_values, data)

                        data_row += 1
                        written_count += 1

        self.logger.info(f"æ•°æ®ç»„ {group_config.get('description', '')} å†™å…¥å®Œæˆï¼Œå…±å†™å…¥ {written_count} è¡Œæ•°æ®")

    def check_and_highlight(self, cell, numeric_values, limit_data):
        """æ£€æŸ¥æ•°å€¼æ˜¯å¦è¶…é™å¹¶é«˜äº®æ˜¾ç¤ºï¼ˆåŒ…æ‹¬"Over"å€¼ï¼‰- åªæ¯”è¾ƒç»å¯¹å€¼å¤§å°"""
        if not numeric_values:
            return

        try:
            highlight_fill = PatternFill(
                start_color=self.config.HIGHLIGHT_COLOR,
                end_color=self.config.HIGHLIGHT_COLOR,
                fill_type="solid"
            )

            should_highlight = False

            for i, val in enumerate(numeric_values):
                # ğŸ†• ä¿®æ”¹ï¼šå¯¹äº"Over"å€¼ï¼ˆæ— ç©·å¤§ï¼‰ï¼Œç›´æ¥æ ‡è®°ä¸ºå¼‚å¸¸
                if val == float('inf'):
                    should_highlight = True
                    self.logger.debug(f"Overå€¼è¢«æ ‡è®°ä¸ºå¼‚å¸¸")
                    continue

                # ğŸ†• å–ç»å¯¹å€¼è¿›è¡Œæ¯”è¾ƒ
                abs_val = abs(val)

                # æ£€æŸ¥æœ€å°é™å€¼
                if (i < len(limit_data['min_limits']) and
                        limit_data['min_limits'][i] is not None):

                    min_limit = self.clean_numeric_value(limit_data['min_limits'][i])
                    if min_limit is not None:
                        # ğŸ†• å–ç»å¯¹å€¼æ¯”è¾ƒ
                        abs_min_limit = abs(min_limit)
                        if abs_val < abs_min_limit:
                            should_highlight = True
                            self.logger.debug(f"ç»å¯¹å€¼ {abs_val} ä½äºæœ€å°é™å€¼ç»å¯¹å€¼ {abs_min_limit} (åŸå€¼: {val}, åŸé™å€¼: {min_limit})")

                # æ£€æŸ¥æœ€å¤§é™å€¼
                if (i < len(limit_data['max_limits']) and
                        limit_data['max_limits'][i] is not None):

                    max_limit = self.clean_numeric_value(limit_data['max_limits'][i])
                    if max_limit is not None:
                        # ğŸ†• å–ç»å¯¹å€¼æ¯”è¾ƒ
                        abs_max_limit = abs(max_limit)
                        if abs_val > abs_max_limit:
                            should_highlight = True
                            self.logger.debug(f"ç»å¯¹å€¼ {abs_val} è¶…è¿‡æœ€å¤§é™å€¼ç»å¯¹å€¼ {abs_max_limit} (åŸå€¼: {val}, åŸé™å€¼: {max_limit})")

            if should_highlight:
                cell.fill = highlight_fill

        except Exception as e:
            self.logger.warning(f"é«˜äº®æ£€æŸ¥å¤±è´¥: {str(e)}")

    def process_all_reports(self):
        """å¤„ç†æ‰€æœ‰æŠ¥å‘Š"""
        source_dir = Path(self.config.SOURCE_DIR)
        template_path = Path(self.config.TEMPLATE_DIR) / self.config.TEMPLATE_FILE
        output_dir = Path(self.config.OUTPUT_DIR)

        self.logger.info(f"æºæ–‡ä»¶ç›®å½•: {source_dir}")
        self.logger.info(f"æ¨¡æ¿æ–‡ä»¶: {template_path}")
        self.logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")

        if not template_path.exists():
            self.logger.error(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
            return

        excel_files = list(source_dir.glob("*.xlsx")) + list(source_dir.glob("*.xls"))

        if not excel_files:
            self.logger.warning(f"åœ¨ {source_dir} ä¸­æœªæ‰¾åˆ°Excelæºæ–‡ä»¶")
            return

        self.logger.info(f"æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶: {[f.name for f in excel_files]}")

        processed_count = 0
        error_count = 0

        for file_path in excel_files:
            try:
                self.logger.info(f"å¼€å§‹å¤„ç†: {file_path.name}")

                df = self.read_source_data(file_path)
                if df is None:
                    error_count += 1
                    continue

                test_info = self.extract_test_info(df)
                test_data = self.extract_test_data(df)
                template_data = self.map_to_template_items(test_info)

                output_file = output_dir / f"processed_{file_path.stem}.xlsx"

                self.write_to_template(template_path, output_file, template_data, test_data)
                processed_count += 1

            except Exception as e:
                error_count += 1
                self.logger.error(f"å¤„ç†æ–‡ä»¶ {file_path.name} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")

                if not self.config.ERROR_HANDLING['continue_on_error']:
                    break

        self.logger.info(f"å¤„ç†å®Œæˆï¼æˆåŠŸ: {processed_count}, å¤±è´¥: {error_count}")


def main():
    """ä¸»å‡½æ•°"""
    processor = SmartReportProcessor()
    processor.process_all_reports()


if __name__ == "__main__":
    main()
